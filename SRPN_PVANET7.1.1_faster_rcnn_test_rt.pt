#Data
name: "PVA-NET"

scale: 600
max_size: 1000
multiple: 32
mean_value: 102.9801
mean_value: 115.9465
mean_value: 122.7717
nms_thresh: 0.3
conf_thresh: 0.7
class_name: "bicycle"
class_name: "bird"
class_name: "bus"
class_name: "car"
class_name: "cat"
class_name: "dog"
class_name: "horse"
class_name: "motorbike"
class_name: "person"
class_name: "train"
class_name: "aeroplane"
class_name: "boat"
class_name: "bottle"
class_name: "chair"
class_name: "cow"
class_name: "diningtable"
class_name: "pottedplant"
class_name: "sheep"
class_name: "sofa"
class_name: "tvmonitor"

input: "data"
input_shape {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}

input: "im_info"
input_shape {
  dim: 1
  dim: 4
}

#ConvNet
################################################################################
## Conv 1
################################################################################
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    pad: 1
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}

################################################################################
## Conv 2
################################################################################
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_2"
  top: "conv2_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}

################################################################################
## Conv 3
################################################################################
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 3
    pad: 1
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}

################################################################################
## Conv 4
################################################################################
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv4_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    kernel_size: 3
    pad: 1
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}

################################################################################
## Conv 5
################################################################################
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv5_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
	name: "downsample"
	type: "Pooling"
	bottom: "conv3_3"
	top: "downsample"
	pooling_param {
		kernel_size: 3
		stride: 2
		pad: 0
		pool: MAX
	}
}
layer {
    name: "upsample"
    type: "Deconvolution"
    bottom: "conv5_3"
    top: "upsample"
    convolution_param {
        kernel_size: 4
        stride: 2
        num_output: 512
        group: 512
        pad: 1
        weight_filler: {type: "bilinear" } 
        bias_term: false
    }
    param { lr_mult: 0 decay_mult: 0}
}
layer {
  name: "concat"
  bottom: "downsample"
  bottom: "conv4_3"
  bottom: "upsample"
  top: "concat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "convf"
  type: "Convolution"
  bottom: "concat"
  top: "convf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "reluf"
  type: "ReLU"
  bottom: "convf"
  top: "convf"
}

#RPN

layer {
  name: "rpn_conv1"
  type: "Convolution"
  bottom: "convf"
  top: "rpn_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1 pad: 0 stride: 1
  }
}
layer {
  name: "rpn_relu1"
  type: "ReLU"
  bottom: "rpn_conv1"
  top: "rpn_conv1"
}

layer {
  name: "rpn_conv3"
  type: "Convolution"
  bottom: "convf"
  top: "rpn_conv3"
  convolution_param {
    num_output: 256
    kernel_size: 3 pad: 1 stride: 1
  }
}
layer {
  name: "rpn_relu3"
  type: "ReLU"
  bottom: "rpn_conv3"
  top: "rpn_conv3"
}

layer {
  name: "rpn_conv5"
  type: "Convolution"
  bottom: "convf"
  top: "rpn_conv5"
  convolution_param {
    num_output: 128
    kernel_size: 5 pad: 2 stride: 1
  }
}
layer {
  name: "rpn_relu5"
  type: "ReLU"
  bottom: "rpn_conv5"
  top: "rpn_conv5"
}
#------------

layer {
  name: "rpn_cls_score1"
  type: "Convolution"
  bottom: "rpn_conv1"
  top: "rpn_cls_score1"
  convolution_param {
    num_output: 50   # 2(bg/fg) * 25(anchors)
    kernel_size: 1 pad: 0 stride: 1
  }
}
layer {
  name: "rpn_bbox_pred1"
  type: "Convolution"
  bottom: "rpn_conv1"
  top: "rpn_bbox_pred1"
  convolution_param {
    num_output: 100   # 4 * 25(anchors)
    kernel_size: 1 pad: 0 stride: 1
  }
}

layer {
  name: "rpn_cls_score3"
  type: "Convolution"
  bottom: "rpn_conv3"
  top: "rpn_cls_score3"
  convolution_param {
    num_output: 50   # 2(bg/fg) * 25(anchors)
    kernel_size: 1 pad: 0 stride: 1
  }
}
layer {
  name: "rpn_bbox_pred3"
  type: "Convolution"
  bottom: "rpn_conv3"
  top: "rpn_bbox_pred3"
  convolution_param {
    num_output: 100   # 4 * 25(anchors)
    kernel_size: 1 pad: 0 stride: 1
  }
}

layer {
  name: "rpn_cls_score5"
  type: "Convolution"
  bottom: "rpn_conv5"
  top: "rpn_cls_score5"
  convolution_param {
    num_output: 50   # 2(bg/fg) * 25(anchors)
    kernel_size: 1 pad: 0 stride: 1
  }
}
layer {
  name: "rpn_bbox_pred5"
  type: "Convolution"
  bottom: "rpn_conv5"
  top: "rpn_bbox_pred5"
  convolution_param {
    num_output: 100   # 4 * 25(anchors)
    kernel_size: 1 pad: 0 stride: 1
  }
}
#-------

layer {
  name: "rpn_cls_score"
  type: "Concat"
  bottom: "rpn_cls_score1"
  bottom: "rpn_cls_score3"
  bottom: "rpn_cls_score5"
  top: "rpn_cls_score"
}
layer {
  name: "rpn_bbox_pred"
  type: "Concat"
  bottom: "rpn_bbox_pred1"
  bottom: "rpn_bbox_pred3"
  bottom: "rpn_bbox_pred5"
  top: "rpn_bbox_pred"
}


layer {
   bottom: "rpn_cls_score"
   top: "rpn_cls_score_reshape"
   name: "rpn_cls_score_reshape"
   type: "Reshape"
   reshape_param { shape { dim: 0 dim: 2 dim: -1 dim: 0 } }
}

#Proposal
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: 'rpn_cls_prob_reshape'
  type: 'Reshape'
  bottom: 'rpn_cls_prob'
  top: 'rpn_cls_prob_reshape'
  reshape_param { shape { dim: 0 dim: 150 dim: -1 dim: 0 } }
}
layer {
  name: 'proposal'
  type: 'Proposal'
  bottom: 'rpn_cls_prob_reshape'
  bottom: 'rpn_bbox_pred'
  bottom: 'im_info'
  top: 'rois'
  proposal_param {
    feat_stride: 16
    base_size: 16
    ratio: 0.5 ratio: 0.667 ratio: 1 ratio: 1.5 ratio: 2
    scale: 3 scale: 6 scale: 9 scale: 16 scale: 32
    copys: 3
    pre_nms_topn: 6000
    post_nms_topn: 300
    nms_thresh: 0.7
    min_size: 16     
  }
}

#RCNN
layer {
  name: "roi_pool_conv5"
  type: "ROIPooling"
  bottom: "convf"
  bottom: "rois"
  top: "roi_pool_conv5"
  roi_pooling_param {
    pooled_w: 6
    pooled_h: 6
    spatial_scale: 0.0625 # 1/16
  }
}
layer {
  name: "fc6_L"
  type: "InnerProduct"
  bottom: "roi_pool_conv5"
  top: "fc6_L"
  inner_product_param {
    num_output: 512
    bias_term: false
  }
}
layer {
  name: "fc6_U"
  type: "InnerProduct"
  bottom: "fc6_L"
  top: "fc6_U"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6_U"
  top: "fc6_U"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6_U"
  top: "fc6_U"
  dropout_param {
    dropout_ratio: 0.5
    scale_train: false
  }
}

layer {
  name: "fc7_L"
  type: "InnerProduct"
  bottom: "fc6_U"
  top: "fc7_L"
  inner_product_param {
    num_output: 128
    bias_term: false
  }
}
layer {
  name: "fc7_U"
  type: "InnerProduct"
  bottom: "fc7_L"
  top: "fc7_U"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7_U"
  top: "fc7_U"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7_U"
  top: "fc7_U"
  dropout_param {
    dropout_ratio: 0.5
    scale_train: false
  }
}

layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7_U"
  top: "cls_score"
  inner_product_param {
    num_output: 21
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7_U"
  top: "bbox_pred"
  inner_product_param {
    num_output: 84
  }
}
layer {
  name: "cls_prob"
  type: "Softmax"
  bottom: "cls_score"
  top: "cls_prob"
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
